{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling for Used Car Prices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizes pandas for data handling, sklearn for preprocessing (including one-hot encoding and scaling with **StandardScaler**), and various models including **HistGradientBoostingRegressor**, **RandomForestRegressor**, **Ridge**, and **StackingRegressor** for predictive modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoeyespinoza/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/zoeyespinoza/anaconda3/lib/python3.10/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:15: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Keep the 'id' column\n",
    "test_ids = test_data['id']\n",
    "\n",
    "# Convert categorical variables using one-hot encoding\n",
    "train_data = pd.get_dummies(train_data)\n",
    "test_data = pd.get_dummies(test_data)\n",
    "\n",
    "# Align the train and test data \n",
    "train_data, test_data = train_data.align(test_data, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Remove the 'price' column from the test data\n",
    "if 'price' in test_data.columns:\n",
    "    test_data = test_data.drop(['price'], axis=1)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = train_data.select_dtypes(include=['int64', 'float64']).columns.drop('price')\n",
    "train_data[numerical_columns] = scaler.fit_transform(train_data[numerical_columns])\n",
    "test_data[numerical_columns] = scaler.transform(test_data[numerical_columns])\n",
    "\n",
    "X = train_data.drop(['price'], axis=1)\n",
    "y = train_data['price']\n",
    "\n",
    "assert test_data.shape[0] == 36183, f\"Expected 36183 rows in test data, but got {test_data.shape[0]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zoeyespinoza/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/zoeyespinoza/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/zoeyespinoza/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/zoeyespinoza/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/zoeyespinoza/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/zoeyespinoza/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/zoeyespinoza/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/zoeyespinoza/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/zoeyespinoza/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/zoeyespinoza/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/zoeyespinoza/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/zoeyespinoza/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END learning_rate=0.05, max_depth=3, max_iter=200, min_samples_leaf=10; total time= 1.5min\n",
      "[CV] END learning_rate=0.05, max_depth=3, max_iter=200, min_samples_leaf=20; total time= 1.5min\n",
      "[CV] END learning_rate=0.05, max_depth=3, max_iter=200, min_samples_leaf=10; total time= 1.7min\n",
      "[CV] END learning_rate=0.05, max_depth=3, max_iter=200, min_samples_leaf=20; total time= 1.7min\n",
      "[CV] END learning_rate=0.05, max_depth=3, max_iter=200, min_samples_leaf=10; total time= 1.8min\n",
      "[CV] END learning_rate=0.01, max_depth=3, max_iter=100, min_samples_leaf=10; total time= 2.1min\n",
      "[CV] END learning_rate=0.01, max_depth=3, max_iter=100, min_samples_leaf=10; total time= 2.1min\n",
      "[CV] END learning_rate=0.01, max_depth=3, max_iter=100, min_samples_leaf=10; total time= 2.1min\n",
      "[CV] END learning_rate=0.05, max_depth=3, max_iter=200, min_samples_leaf=20; total time= 2.2min\n",
      "[CV] END learning_rate=0.05, max_depth=3, max_iter=100, min_samples_leaf=20; total time= 1.1min\n",
      "[CV] END learning_rate=0.05, max_depth=3, max_iter=100, min_samples_leaf=20; total time= 1.3min\n",
      "[CV] END learning_rate=0.05, max_depth=3, max_iter=100, min_samples_leaf=20; total time= 1.5min\n",
      "[CV] END learning_rate=0.1, max_depth=5, max_iter=300, min_samples_leaf=20; total time=  54.6s\n",
      "[CV] END learning_rate=0.1, max_depth=5, max_iter=300, min_samples_leaf=20; total time=  56.3s\n",
      "[CV] END learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=10; total time= 3.0min\n",
      "[CV] END learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=20; total time= 2.4min\n",
      "[CV] END learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=20; total time= 2.3min\n",
      "[CV] END learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=10; total time= 3.0min\n",
      "[CV] END learning_rate=0.01, max_depth=5, max_iter=100, min_samples_leaf=20; total time= 2.4min\n",
      "[CV] END learning_rate=0.1, max_depth=5, max_iter=300, min_samples_leaf=20; total time= 1.1min\n",
      "[CV] END learning_rate=0.01, max_depth=10, max_iter=100, min_samples_leaf=10; total time= 3.1min\n",
      "[CV] END learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=20; total time= 4.8min\n",
      "[CV] END learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=20; total time= 4.9min\n",
      "[CV] END learning_rate=0.01, max_depth=10, max_iter=200, min_samples_leaf=20; total time= 5.3min\n",
      "[CV] END learning_rate=0.05, max_depth=3, max_iter=300, min_samples_leaf=10; total time= 1.1min\n",
      "[CV] END learning_rate=0.05, max_depth=10, max_iter=200, min_samples_leaf=20; total time= 1.5min\n",
      "[CV] END learning_rate=0.05, max_depth=3, max_iter=300, min_samples_leaf=10; total time= 1.2min\n",
      "[CV] END learning_rate=0.05, max_depth=10, max_iter=200, min_samples_leaf=20; total time= 1.5min\n",
      "[CV] END learning_rate=0.05, max_depth=10, max_iter=200, min_samples_leaf=20; total time= 1.7min\n",
      "[CV] END learning_rate=0.05, max_depth=3, max_iter=300, min_samples_leaf=10; total time= 1.3min\n",
      "[CV] END learning_rate=0.01, max_depth=3, max_iter=200, min_samples_leaf=20; total time= 2.9min\n",
      "[CV] END learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=20; total time=  56.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, max_iter=200, min_samples_leaf=20; total time= 2.9min\n",
      "[CV] END learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=20; total time= 1.0min\n",
      "[CV] END learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=20; total time= 1.1min\n",
      "[CV] END learning_rate=0.05, max_depth=3, max_iter=300, min_samples_leaf=50; total time= 1.1min\n",
      "[CV] END learning_rate=0.01, max_depth=3, max_iter=200, min_samples_leaf=20; total time= 3.1min\n",
      "[CV] END learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=50; total time=  58.4s\n",
      "[CV] END learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=10; total time= 3.3min\n",
      "[CV] END learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=50; total time= 1.1min\n",
      "[CV] END learning_rate=0.1, max_depth=5, max_iter=200, min_samples_leaf=50; total time= 1.1min\n",
      "[CV] END learning_rate=0.05, max_depth=3, max_iter=300, min_samples_leaf=50; total time= 1.6min\n",
      "[CV] END learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=10; total time= 3.5min\n",
      "[CV] END learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=10; total time= 3.8min\n",
      "[CV] END learning_rate=0.05, max_depth=10, max_iter=100, min_samples_leaf=10; total time= 1.3min\n",
      "[CV] END learning_rate=0.05, max_depth=3, max_iter=300, min_samples_leaf=50; total time= 1.8min\n",
      "[CV] END learning_rate=0.05, max_depth=10, max_iter=100, min_samples_leaf=10; total time= 1.4min\n",
      "[CV] END learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=20; total time= 1.1min\n",
      "[CV] END learning_rate=0.05, max_depth=10, max_iter=100, min_samples_leaf=10; total time= 1.4min\n",
      "[CV] END learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=20; total time= 1.2min\n",
      "[CV] END learning_rate=0.1, max_depth=3, max_iter=300, min_samples_leaf=20; total time=  56.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, max_iter=100, min_samples_leaf=20; total time=  53.5s\n",
      "[CV] END learning_rate=0.1, max_depth=3, max_iter=300, min_samples_leaf=20; total time= 1.0min\n",
      "[CV] END learning_rate=0.1, max_depth=3, max_iter=300, min_samples_leaf=20; total time= 1.0min\n",
      "[CV] END learning_rate=0.1, max_depth=10, max_iter=100, min_samples_leaf=20; total time= 1.3min\n",
      "[CV] END learning_rate=0.1, max_depth=3, max_iter=100, min_samples_leaf=20; total time=  52.8s\n",
      "[CV] END learning_rate=0.1, max_depth=3, max_iter=100, min_samples_leaf=20; total time=  50.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, max_iter=200, min_samples_leaf=20; total time= 1.0min\n",
      "[CV] END learning_rate=0.05, max_depth=5, max_iter=200, min_samples_leaf=20; total time= 1.0min\n",
      "[CV] END learning_rate=0.05, max_depth=5, max_iter=200, min_samples_leaf=20; total time= 1.0min\n",
      "Best Parameters (Randomized Search): {'min_samples_leaf': 50, 'max_iter': 200, 'max_depth': 5, 'learning_rate': 0.1}\n",
      "Best RMSE (Randomized Search): 73069.64454268749\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameters for Randomized Search\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_leaf': [10, 20, 50]\n",
    "}\n",
    "\n",
    "# Gradient Boosting model\n",
    "gb_model = HistGradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Randomized Search\n",
    "random_search = RandomizedSearchCV(estimator=gb_model, param_distributions=param_distributions, n_iter=20, cv=3, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error', random_state=42)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# best parameters and best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = np.sqrt(-random_search.best_score_)\n",
    "print(f'Best Parameters (Randomized Search): {best_params}')\n",
    "print(f'Best RMSE (Randomized Search): {best_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Best Gradient Boosting): 48176.967086731645\n"
     ]
    }
   ],
   "source": [
    "# Train the Gradient Boosting model with the best parameters\n",
    "best_gb_model = HistGradientBoostingRegressor(**best_params, random_state=42)\n",
    "best_gb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_best_gb = best_gb_model.predict(X_val)\n",
    "\n",
    "# Calculate RMSE \n",
    "rmse_best_gb = np.sqrt(mean_squared_error(y_val, y_pred_best_gb))\n",
    "print(f'RMSE (Best Gradient Boosting): {rmse_best_gb}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Stacking Model): 48085.15815151347\n"
     ]
    }
   ],
   "source": [
    "# Define base models\n",
    "base_models = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
    "    ('gb', HistGradientBoostingRegressor(**best_params, random_state=42))\n",
    "]\n",
    "\n",
    "# Define stacking model\n",
    "stacking_model = StackingRegressor(estimators=base_models, final_estimator=Ridge())\n",
    "\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_stacking = stacking_model.predict(X_val)\n",
    "\n",
    "\n",
    "rmse_stacking = np.sqrt(mean_squared_error(y_val, y_pred_stacking))\n",
    "print(f'RMSE (Stacking Model): {rmse_stacking}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE Scores: [73125.98958589 72561.12099315 50876.61356529 80265.28079763\n",
      " 62340.30210191]\n",
      "Mean CV RMSE: 67833.8614087743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Evaluate model using cross-validation\n",
    "cv_scores = cross_val_score(stacking_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse_scores = np.sqrt(-cv_scores)\n",
    "print(f'Cross-Validation RMSE Scores: {cv_rmse_scores}')\n",
    "print(f'Mean CV RMSE: {cv_rmse_scores.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as submission.csv\n",
      "Submission file zipped as submission.zip\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set using stacking model\n",
    "test_predictions = stacking_model.predict(test_data)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'price': test_predictions\n",
    "})\n",
    "\n",
    "assert submission.shape[0] == 36183, f\"Expected 36183 rows in submission, but got {submission.shape[0]}\"\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print('Submission file saved as submission.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
